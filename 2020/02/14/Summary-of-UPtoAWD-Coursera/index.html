<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/images/manifest.json">
  <meta name="msapplication-config" content="/images/browserconfig.xml">
  <link rel="alternate" href="/atom.xml" title="Yihang" type="application/atom+xml">



<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-material.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":true,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>


  <meta name="description" content="First of all, thanks Dr. Charles Russell Severance  Why I write this summary?  gained certificate from last winter vacation(2019) need to apply this knowledge for data access">
<meta property="og:type" content="article">
<meta property="og:title" content="Summary of Using Python to Access Web Data">
<meta property="og:url" content="http://yihang-li.github.io/2020/02/14/Summary-of-UPtoAWD-Coursera/index.html">
<meta property="og:site_name" content="Yihang">
<meta property="og:description" content="First of all, thanks Dr. Charles Russell Severance  Why I write this summary?  gained certificate from last winter vacation(2019) need to apply this knowledge for data access">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yihang-li.github.io/assets/image-20200214105208294.png">
<meta property="og:image" content="http://yihang-li.github.io/assets/image-20200214180630075.png">
<meta property="og:image" content="http://yihang-li.github.io/assets/image-20200214211642103.png">
<meta property="og:image" content="http://yihang-li.github.io/assets/image-20200215104121294.png">
<meta property="article:published_time" content="2020-02-14T15:21:12.000Z">
<meta property="article:modified_time" content="2020-02-15T16:10:36.673Z">
<meta property="article:author" content="Yihang Li">
<meta property="article:tag" content="python">
<meta property="article:tag" content="coursera">
<meta property="article:tag" content="web">
<meta property="article:tag" content="data access">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yihang-li.github.io/assets/image-20200214105208294.png">

<link rel="canonical" href="http://yihang-li.github.io/2020/02/14/Summary-of-UPtoAWD-Coursera/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Summary of Using Python to Access Web Data | Yihang</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yihang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Never Give Up!</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://Yihang-Li.github.io/2020/02/14/Summary-of-UPtoAWD-Coursera/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://s2.ax1x.com/2020/02/06/1yubPU.jpg">
      <meta itemprop="name" content="Yihang Li">
      <meta itemprop="description" content="description here">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yihang">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Summary of Using Python to Access Web Data<a href="https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name_posts/Summary-of-UPtoAWD-Coursera.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pencil"></i></a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-14 10:21:12" itemprop="dateCreated datePublished" datetime="2020-02-14T10:21:12-05:00">2020-02-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-15 11:10:36" itemprop="dateModified" datetime="2020-02-15T11:10:36-05:00">2020-02-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Notes</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>First of all, thanks Dr. Charles Russell Severance</strong></p>
<blockquote>
<p>Why I write this summary?</p>
<ul>
<li>gained certificate from last winter vacation(2019)</li>
<li>need to apply this knowledge for data access</li>
</ul>
</blockquote>
<p><img src="/assets/image-20200214105208294.png" alt="image-20200214105208294" style="zoom:80%;" /></p>
<a id="more"></a>
<p><a href="https://www.py4e.com/book" target="_blank" rel="noopener">Book Link</a></p>
<h1 id="Chapter-11-Regular-expressions"><a href="#Chapter-11-Regular-expressions" class="headerlink" title="Chapter 11 Regular expressions"></a>Chapter 11 Regular expressions</h1><blockquote>
<p>Regular expressions (regex) are almost their own little programming language for searching and parsing strings.</p>
</blockquote>
<p>_For more detail on regex, see: <a href="https://en.wikipedia.org/wiki/Regular_expression" target="_blank" rel="noopener">wiki</a>, <a href="https://docs.python.org/3.5/library/re.html" target="_blank" rel="noopener">python docs</a>._</p>
<h2 id="Cheat-Sheet"><a href="#Cheat-Sheet" class="headerlink" title="Cheat Sheet"></a>Cheat Sheet</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">symbol</th>
<th style="text-align:center">function</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><span style="color:blue"> <strong>^</strong></span></td>
<td style="text-align:center">Matches the beginning of a line</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>$</strong></span></td>
<td style="text-align:center">Matches the end of the line</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>.</strong></span></td>
<td style="text-align:center">Matches any character (<strong>a wildcard</strong>)</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>\s</strong></span></td>
<td style="text-align:center">Matches whitespace</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>\S</strong></span></td>
<td style="text-align:center">Matches any non-whitespace character</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>?</strong></span></td>
<td style="text-align:center">Repeats a character zero or one time</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>??</strong></span></td>
<td style="text-align:center">Repeats a character zero of one time (<strong>non-greedy</strong>)</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>*</strong></span></td>
<td style="text-align:center">Repeats a character zero or more times</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>*?</strong></span></td>
<td style="text-align:center">Repeats a character zero or more times (<strong>non-greedy</strong>)</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>+</strong></span></td>
<td style="text-align:center">Repeats a character one or more times</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>+?</strong></span></td>
<td style="text-align:center">Repeats a character one or more times (<strong>non-greedy</strong>)</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>[aeiou]</strong></span></td>
<td style="text-align:center">Matches a single character in the listed set</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>[\^XYZ]</strong></span></td>
<td style="text-align:center">Matches a single character not in the listed set</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>[a-z0-9]</strong></span></td>
<td style="text-align:center">The set of  characters can include a range</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>(</strong></span></td>
<td style="text-align:center">Indicates where string extraction is to start</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>)</strong></span></td>
<td style="text-align:center">Indicates where string extraction is to end</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>\b</strong></span></td>
<td style="text-align:center">Matches the empty string only at the start of end of word</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>\B</strong></span></td>
<td style="text-align:center">Matches the empty string not at the start or end of a word</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>\d</strong></span></td>
<td style="text-align:center">Matches any decimal digit (equivalent to [0-9])</td>
</tr>
<tr>
<td style="text-align:center"><span style='color:blue'><strong>\D</strong></span></td>
<td style="text-align:center">Matches any non-digit character (equivalent to [\^0-9])</td>
</tr>
</tbody>
</table>
</div>
<p>_<strong>Note:</strong>_</p>
<blockquote>
<ol>
<li>symbol with repeat function applies to the immediately preceding character(s)</li>
<li>greedy matching: the repeat characters (  <span style='color:blue'><strong>*</strong></span>  and <span style='color:blue'><strong>+</strong></span> ) push outward in both directions to match the largest possible string</li>
<li>non-greedy doesn’t mean that the regex will try to find the shortest substring by varying the start index. It just means that if there’s a substring which starts at index 0 and matches the regex, the engine will stop as soon as possible </li>
<li>escape character: by prefixing with a backslash. i.e. \\$ indicate dollar sign instead of the wildcard.</li>
</ol>
</blockquote>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><h3 id="Case-1"><a href="#Case-1" class="headerlink" title="Case 1"></a>Case 1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Search for lines that start with From and have an at sign</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">hand = open(<span class="string">'mbox-short.txt'</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> hand:</span><br><span class="line">    line = line.rstrip()</span><br><span class="line">    <span class="keyword">if</span> re.search(<span class="string">'^From:.+@'</span>, line):</span><br><span class="line">        print(line)</span><br></pre></td></tr></table></figure>
<p>The search string <strong>^From:.+@</strong> will successfully match lines that start with “<strong>From:</strong>“, followed by one or more characters (<strong>.+</strong>), followed by an at-sign. So this will match the following line:<br><strong>From: stephen.marquard@uct.ac.za</strong></p>
<h3 id="Case-2"><a href="#Case-2" class="headerlink" title="Case 2"></a>Case 2</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">x = <span class="string">"We just received $10.00 for cookies."</span></span><br><span class="line">y = re.findall(<span class="string">'\$[0-9.]+'</span>, x)</span><br></pre></td></tr></table></figure>
<p>Since we prefix the dollar sign with a backslash, it actually matches the dollar sign in the input string instead of matching the “end of line”, and the rest of the regular expression matches one or more digits or the period character.</p>
<p>Note: inside square brackets, characters are not “special”. So, when we say <strong>[0-9.]</strong>, it really means digits or a period . Outside of square brackets, a period is the “wildcard” character and matches any character. Inside square brackets, the period is a period.</p>
<hr>
<h1 id="Chapter-12-Networked-Programs"><a href="#Chapter-12-Networked-Programs" class="headerlink" title="Chapter 12 Networked Programs"></a>Chapter 12 Networked Programs</h1><h2 id="12-1-Hypertext-Transfer-Protocol-HTTP"><a href="#12-1-Hypertext-Transfer-Protocol-HTTP" class="headerlink" title="12.1 Hypertext Transfer Protocol - HTTP"></a>12.1 Hypertext Transfer Protocol - HTTP</h2><blockquote>
<p><strong>Socket/TCP Connections</strong><br>A network connection between two applications where the applications can send and receive data in either direction.</p>
<p><strong>TCP Port Numbers</strong><br>A number that generally indicates which application you are contacting when you make a socket connection to a server. As an example, web traffic usually uses port 80 while email traffic uses port 25.</p>
<p><strong>Protocol</strong><br>A protocol is a set of precise rules that all parties follow so we can predict each other’s behavior. In a sense the two applications at either end of the socket are doing a dance and making sure not to step on each other’s toes.</p>
</blockquote>
<p><a href="http://www.w3.org/Protocols/rfc2616/rfc2616.txt" target="_blank" rel="noopener">HyperText Transfer Protocol</a>, a long and complex 176-page document with a lot of detail. If you find it interesting, feel free to read it all. But if you take a look around page 36 of RFC2616 you will find the syntax for the GET request. </p>
<h2 id="12-2-The-world’s-simplest-web-browser"><a href="#12-2-The-world’s-simplest-web-browser" class="headerlink" title="12.2 The world’s simplest web browser"></a>12.2 The world’s simplest web browser</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/socket1.py</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line">mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">mysock.connect((<span class="string">'data.pr4e.org'</span>, <span class="number">80</span>))</span><br><span class="line">cmd = <span class="string">'GET http://data.pr4e.org/romeo.txt HTTP/1.0\r\n\r\n'</span>.encode()</span><br><span class="line">mysock.send(cmd)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    data = mysock.recv(<span class="number">512</span>)</span><br><span class="line">    <span class="keyword">if</span> len(data) &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(data.decode(), end = <span class="string">''</span>)</span><br><span class="line">mysock.close()</span><br></pre></td></tr></table></figure>
<p><img src="/assets/image-20200214180630075.png" alt="image-20200214180630075" style="zoom:80%;" /></p>
<p>Output:</p>
<blockquote>
<p>HTTP/1.1 200 OK<br>Date: Fri, 14 Feb 2020 23:05:30 GMT<br>Server: Apache/2.4.18 (Ubuntu)<br>Last-Modified: Sat, 13 May 2017 11:22:22 GMT<br>ETag: “a7-54f6609245537”<br>Accept-Ranges: bytes<br>Content-Length: 167<br>Cache-Control: max-age=0, no-cache, no-store, must-revalidate<br>Pragma: no-cache<br>Expires: Wed, 11 Jan 1984 05:00:00 GMT<br>Connection: close<br>Content-Type: text/plain</p>
<p>But soft what light through yonder window breaks<br>It is the east and Juliet is the sun<br>Arise fair sun and kill the envious moon<br>Who is already sick and pale with grief</p>
</blockquote>
<h2 id="12-3-Retrieving-an-image-over-HTTP"><a href="#12-3-Retrieving-an-image-over-HTTP" class="headerlink" title="12.3 Retrieving an image over HTTP"></a>12.3 Retrieving an image over HTTP</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/urljpeg.py</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'data.pr4e.org'</span></span><br><span class="line">PORT = <span class="number">80</span></span><br><span class="line">mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">mysock.connect((HOST, PORT))</span><br><span class="line">mysock.sendall(<span class="string">b'GET http://data.pr4e.org/cover3.jpg HTTP/1.0\r\n\r\n'</span>)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line">picture = <span class="string">b''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    data = mysock.recv(<span class="number">5120</span>)</span><br><span class="line">    <span class="keyword">if</span> (len(data) &lt; <span class="number">1</span>): <span class="keyword">break</span></span><br><span class="line">    time.sleep(<span class="number">0.25</span>)</span><br><span class="line">    count = count + len(data)</span><br><span class="line">    print(len(data), count)</span><br><span class="line">    picture = picture + data</span><br><span class="line"></span><br><span class="line">mysock.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Look for the end of the header (2 CRLF)</span></span><br><span class="line">pos = picture.find(<span class="string">b'\r\n\r\n'</span>)</span><br><span class="line">print(<span class="string">'Header length'</span>, pos)</span><br><span class="line">print(picture[:pos].decode())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Skip past the header and save the picture data</span></span><br><span class="line">picture = picture[pos+<span class="number">4</span>:]</span><br><span class="line">fhand = open(<span class="string">'stuff.jpg'</span>, <span class="string">'wb'</span>)</span><br><span class="line">fhand.write(picture)</span><br><span class="line">fhand.close()</span><br></pre></td></tr></table></figure>
<p>Output:</p>
<blockquote>
<p>1408 1408<br>5120 6528<br>5120 11648<br>…… ……<br>5120 221568<br>3920 230608<br>Header length 394<br>HTTP/1.1 200 OK<br>Date: Fri, 14 Feb 2020 23:21:44 GMT<br>Server: Apache/2.4.18 (Ubuntu)<br>Last-Modified: Mon, 15 May 2017 12:27:40 GMT<br>ETag: “38342-54f8f2e5b6277”<br>Accept-Ranges: bytes<br>Content-Length: 230210<br>Vary: Accept-Encoding<br>Cache-Control: max-age=0, no-cache, no-store, must-revalidate<br>Pragma: no-cache<br>Expires: Wed, 11 Jan 1984 05:00:00 GMT<br>Connection: close<br>Content-Type: image/jpeg</p>
</blockquote>
<p>There is a buffer between the server making <code>send()</code> requests and our application making <code>recv()</code> requests. When we run the program with the delay in place, at some point the server might fill up the buffer in the socket and be forced to pause until our program starts to empty the buffer.<br>The pausing of either the sending application or the receiving application is called “<strong>flow control</strong>“.</p>
<h2 id="12-4-Retrieving-web-pages-with-urllib"><a href="#12-4-Retrieving-web-pages-with-urllib" class="headerlink" title="12.4 Retrieving web pages with urllib"></a>12.4 Retrieving web pages with urllib</h2><blockquote>
<p><strong>urllib</strong>: does all the socket work for us and makes web pages look like a file.</p>
</blockquote>
<p>Using <code>urllib</code>, you can treat a web page much like a file. You simply indicate which web page you would like to retrieve and <code>urllib</code> handles all of the HTTP protocol and header details.</p>
<p>The equivalent code to read the <code>romeo.txt</code> file from the web using <code>urllib</code> is as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/urllib1.py</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">fhand = urllib.request.urlopen(<span class="string">'http://data.pr4e.org/romeo.txt'</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fhand:</span><br><span class="line">    print(line.decode().strip())</span><br></pre></td></tr></table></figure>
<p>When the program runs, we only see the output of the contents of the file. The headers are still sent, but the <code>urllib</code> code consumes the headers and only returns the data to us.</p>
<p>Output:</p>
<blockquote>
<p>But soft what light through yonder window breaks<br>It is the east and Juliet is the sun<br>Arise fair sun and kill the envious moon<br>Who is already sick and pale with grief</p>
</blockquote>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>retrieve the data for <code>romeo.txt</code> and compute the frequency of each word in the file</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Code: http:&#x2F;&#x2F;www.py4e.com&#x2F;code3&#x2F;urlwords.py</span><br><span class="line">import urllib.request, urllib.parse, urllib.error</span><br><span class="line"></span><br><span class="line">fhand &#x3D; urllib.request.urlopen(&#39;http:&#x2F;&#x2F;data.pr4e.org&#x2F;romeo.txt&#39;)</span><br><span class="line"></span><br><span class="line">counts &#x3D; dict()</span><br><span class="line">for line in fhand:</span><br><span class="line">    words &#x3D; line.decode().split()</span><br><span class="line">    for word in words:</span><br><span class="line">        counts[word] &#x3D; counts.get(word, 0) + 1</span><br><span class="line">print(counts)</span><br></pre></td></tr></table></figure>
<p>Output:</p>
<blockquote>
<p>{‘But’: 1, ‘soft’: 1, ‘what’: 1, ‘light’: 1, ‘through’: 1, ‘yonder’: 1, ‘window’: 1, ‘breaks’: 1, ‘It’: 1, ‘is’: 3, ‘the’: 3, ‘east’: 1, ‘and’: 3, ‘Juliet’: 1, ‘sun’: 2, ‘Arise’: 1, ‘fair’: 1, ‘kill’: 1, ‘envious’: 1, ‘moon’: 1, ‘Who’: 1, ‘already’: 1, ‘sick’: 1, ‘pale’: 1, ‘with’: 1, ‘grief’: 1}</p>
</blockquote>
<h2 id="12-5-Reading-binary-files-using-urllib"><a href="#12-5-Reading-binary-files-using-urllib" class="headerlink" title="12.5 Reading binary files using urllib"></a>12.5 Reading binary files using urllib</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Code: http://www.py4e.com/code3/curl2.py</span></span><br><span class="line"><span class="keyword">import</span> urllib.request, urllib.parse, urllib.error</span><br><span class="line"></span><br><span class="line">img = urllib.request.urlopen(<span class="string">'http://data.pr4e.org/cover3.jpg'</span>)</span><br><span class="line">fhand = open(<span class="string">'cover3.jpg'</span>, <span class="string">'wb'</span>)</span><br><span class="line">size = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    info = img.read(<span class="number">100000</span>)</span><br><span class="line">    <span class="keyword">if</span> len(info) &lt; <span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line">    size += len(info)</span><br><span class="line">    fhand.write(info)</span><br><span class="line">print(size, <span class="string">'characters copied.'</span>)</span><br><span class="line">fhand.close()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>read only 100,000 characters at a time and then write those characters to the cover.jpg file before retrieving the next 100,000 characters of data from the web.</p>
</blockquote>
<h2 id="12-6-Parsing-HTML-and-scraping-the-web"><a href="#12-6-Parsing-HTML-and-scraping-the-web" class="headerlink" title="12.6 Parsing HTML and scraping the web"></a>12.6 Parsing HTML and scraping the web</h2><blockquote>
<p>One of the common uses of the <code>urllib</code> capability in Python is to <em>scrape</em> the web. Web scraping is when we write a program that pretends to be a web browser and retrieves pages, then examines the data in those pages looking for patterns.</p>
<p>As an example, a search engine such as Google will look at the source of one web page and extract the links to other pages and retrieve those pages, extracting links, and so on. Using this technique, Google <em>spiders</em> its way through nearly all of the pages on the web.</p>
<p>Google also uses the frequency of links from pages it finds to a particular page as one measure of how “important” a page is and how high the page should appear in its search results.</p>
</blockquote>
<h2 id="12-7-Parsing-HTML-using-regular-expressions"><a href="#12-7-Parsing-HTML-using-regular-expressions" class="headerlink" title="12.7 Parsing HTML using regular expressions"></a>12.7 Parsing HTML using regular expressions</h2><p>For the simple webpage:</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>The First Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">If you like, you can switch to the</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.dr-chuck.com/page2.htm"</span>&gt;</span></span><br><span class="line">Second Page<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.</span><br><span class="line"><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>We can construct a well-formed regular expression to match and extract the link values from the above text as follows:</p>
<blockquote>
<p>href=”(<a href="http://.+?" target="_blank" rel="noopener">http://.+?</a>)”</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/urlregex.py</span></span><br><span class="line"><span class="keyword">import</span> urllib.request, urllib.parse, urllib.error</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">url = input(<span class="string">'Enter - '</span>)</span><br><span class="line">html = urllib.request.urlopen(url).read()</span><br><span class="line">links = re.findall(<span class="string">b'href="(http://.+?)"'</span>, html)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">    print(link.decode())</span><br></pre></td></tr></table></figure>
<p>Output:</p>
<blockquote>
<p>Enter -  <a href="https://yihang-li.github.io/">https://yihang-li.github.io/</a><br><a href="http://yihang-li.github.io/">http://yihang-li.github.io/</a><br><a href="http://Yihang-Li.github.io/2020/02/14/Summary-of-UPtoAWD-Coursera/">http://Yihang-Li.github.io/2020/02/14/Summary-of-UPtoAWD-Coursera/</a><br><a href="http://Yihang-Li.github.io/2020/02/10/Summary-for-visualization-of-geospatial-data/">http://Yihang-Li.github.io/2020/02/10/Summary-for-visualization-of-geospatial-data/</a><br><a href="http://Yihang-Li.github.io/2020/02/08/Notes-of-Gaussian-Processes-for-Machine-Learning/">http://Yihang-Li.github.io/2020/02/08/Notes-of-Gaussian-Processes-for-Machine-Learning/</a><br><a href="http://Yihang-Li.github.io/2020/02/05/Hello-Echo/">http://Yihang-Li.github.io/2020/02/05/Hello-Echo/</a><br><a href="http://Yihang-Li.github.io/2020/02/05/hello-world/">http://Yihang-Li.github.io/2020/02/05/hello-world/</a></p>
</blockquote>
<h2 id="12-8-Parsing-HTML-using-BeautifulSoup"><a href="#12-8-Parsing-HTML-using-BeautifulSoup" class="headerlink" title="12.8 Parsing HTML using BeautifulSoup"></a>12.8 Parsing HTML using BeautifulSoup</h2><blockquote>
<p><strong>BeautifulSoup</strong> tolerates highly flawed HTML and still lets you easily extract the data you need. See <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="noopener">docs</a>.</p>
</blockquote>
<p>We will use <code>urllib</code> to read the page and then use <code>BeautifulSoup</code> to extract the <code>href</code> attributes from the anchor (<code>a</code>) tags.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/urllinks.py</span></span><br><span class="line"><span class="keyword">import</span> urllib.request, urllib.parse, urllib.error</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ignore SSL certificate errors</span></span><br><span class="line">ctx = ssl.create_default_context()</span><br><span class="line">ctx.check_hostname = <span class="literal">False</span></span><br><span class="line">ctx.verify_mode = ssl.CERT_NONE</span><br><span class="line"></span><br><span class="line">url = input(<span class="string">'Enter - '</span>)</span><br><span class="line">html = urllib.request.urlopen(url, context=ctx).read()</span><br><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrieve all of the anchor tags</span></span><br><span class="line">tags = soup(<span class="string">'a'</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> tags:</span><br><span class="line">    print(tag.get(<span class="string">'href'</span>, <span class="literal">None</span>))</span><br></pre></td></tr></table></figure>
<p>The program prompts for a web address, then opens the web page, reads the data and passes the data to the BeautifulSoup parser, and then retrieves all of the anchor tags and prints out the <code>href</code> attribute for each tag.</p>
<p>You can use BeautifulSoup to pull out various parts of each tag as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/urllink2.py</span></span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ignore SSL certificate errors</span></span><br><span class="line">ctx = ssl.create_default_context()</span><br><span class="line">ctx.check_hostname = <span class="literal">False</span></span><br><span class="line">ctx.verify_mode = ssl.CERT_NONE</span><br><span class="line"></span><br><span class="line">url = input(<span class="string">'Enter - '</span>)</span><br><span class="line">html = urlopen(url, context=ctx).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># html.parser is the HTML parser included in the standard Python 3 library.</span></span><br><span class="line"><span class="comment"># information on other HTML parsers is here:</span></span><br><span class="line"><span class="comment"># http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser</span></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrieve all of the anchor tags</span></span><br><span class="line">tags = soup(<span class="string">'a'</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> tags:</span><br><span class="line">    <span class="comment"># Look at the parts of a tag</span></span><br><span class="line">    print(<span class="string">'TAG:'</span>, tag)</span><br><span class="line">    print(<span class="string">'URL:'</span>, tag.get(<span class="string">'href'</span>, <span class="literal">None</span>))</span><br><span class="line">    print(<span class="string">'Contents:'</span>, tag.contents[<span class="number">0</span>])</span><br><span class="line">    print(<span class="string">'Attrs:'</span>, tag.attrs)</span><br></pre></td></tr></table></figure>
<h2 id="12-9-Something-more"><a href="#12-9-Something-more" class="headerlink" title="12.9 Something more"></a>12.9 Something more</h2><blockquote>
<p><strong>Scrape</strong><br>When a program pretends to be a web browser and retrieves a web page, then looks at the web page content. Often programs are following the links in one page to find the next page so they can traverse a network of pages or a social network.</p>
<p><strong>Spider</strong><br>The act of a web search engine retrieving a page and then all the pages linked from a page and so on until they have nearly all of the pages on the Internet which they use to build their search index.</p>
<p><strong>ASCII</strong><br>American Standard Code for Information Interchange</p>
<p>Each character is represented by a number between 0 and 256 stored in 8 bits of memory(a byte of memory)</p>
<p>The <strong>ord()</strong> function tells us the numeric value of a simple ASCII character<br>(On the opposite, we can use <strong>chr()</strong>)</p>
<p>In Python3, all strings are unicode. When we read data from an external resource, we must decode it based on the character set so it is properly represented in Python3 as a string.</p>
</blockquote>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>The TCP/IP gives us pipes/sockets between applications</li>
<li>We designed application protocols to make use of these pipes</li>
<li>HyperText Transfer Protocol (HTTP) is a simple yet powerful proctocol</li>
<li>Python has good support for sockets, HTTP, and HTML parsing</li>
</ul>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><h1 id="Chapter-13-Using-Web-Services"><a href="#Chapter-13-Using-Web-Services" class="headerlink" title="Chapter 13 Using Web Services"></a>Chapter 13 Using Web Services</h1><h2 id="13-1-eXtensible-Markup-Language-XML"><a href="#13-1-eXtensible-Markup-Language-XML" class="headerlink" title="13.1 eXtensible Markup Language - XML"></a>13.1 eXtensible Markup Language - XML</h2><p>XML looks similar to HTML but more structured. See a sample below:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">person</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>Chuck<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">phone</span> <span class="attr">type</span>=<span class="string">"intl"</span>&gt;</span></span><br><span class="line">     +1 734 303 4456</span><br><span class="line">  <span class="tag">&lt;/<span class="name">phone</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">email</span> <span class="attr">hide</span>=<span class="string">"yes"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">person</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Often it is helpful to think of an XML document as a tree structure where there is a top tag <code>person</code> and other tags such as <code>phone</code> are drawn as <em>children</em> of their parent nodes.</p>
<p><img src="/assets/image-20200214211642103.png" alt="image-20200214211642103" style="zoom:80%;" /></p>
<h2 id="13-2-Parsing-XML"><a href="#13-2-Parsing-XML" class="headerlink" title="13.2 Parsing XML"></a>13.2 Parsing XML</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/xml1.py</span></span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line">data = <span class="string">'''</span></span><br><span class="line"><span class="string">&lt;person&gt;</span></span><br><span class="line"><span class="string">  &lt;name&gt;Chuck&lt;/name&gt;</span></span><br><span class="line"><span class="string">  &lt;phone type="intl"&gt;</span></span><br><span class="line"><span class="string">     +1 734 303 4456</span></span><br><span class="line"><span class="string">   &lt;/phone&gt;</span></span><br><span class="line"><span class="string">   &lt;email hide="yes"/&gt;</span></span><br><span class="line"><span class="string">&lt;/person&gt;'''</span></span><br><span class="line"></span><br><span class="line">tree = ET.fromstring(data)</span><br><span class="line">print(<span class="string">'Name:'</span>, tree.find(<span class="string">'name'</span>).text)</span><br><span class="line">print(<span class="string">'Attr:'</span>, tree.find(<span class="string">'email'</span>).get(<span class="string">'hide'</span>))</span><br></pre></td></tr></table></figure>
<p>Output:</p>
<blockquote>
<p>Name: Chuck<br>Attr: yes</p>
</blockquote>
<p>Calling <code>fromstring</code> converts the string representation of the XML into a “tree” of XML nodes. When the XML is in a tree, we have a series of methods we can call to extract portions of data from the XML.</p>
<p>The <code>find</code> function searches through the XML tree and retrieves a <em>node</em> that matches the specified tag. Each node can have some text, some attributes (like hide), and some “child” nodes. Each node can be the top of a tree of nodes.</p>
<h2 id="13-3-Looping-through-nodes"><a href="#13-3-Looping-through-nodes" class="headerlink" title="13.3 Looping through nodes"></a>13.3 Looping through nodes</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/xml2.py</span></span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line">input = <span class="string">'''</span></span><br><span class="line"><span class="string">&lt;stuff&gt;</span></span><br><span class="line"><span class="string">    &lt;users&gt;</span></span><br><span class="line"><span class="string">        &lt;user x="2"&gt;</span></span><br><span class="line"><span class="string">            &lt;id&gt;001&lt;/id&gt;</span></span><br><span class="line"><span class="string">            &lt;name&gt;Chuck&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;/user&gt;</span></span><br><span class="line"><span class="string">        &lt;user x="7"&gt;</span></span><br><span class="line"><span class="string">            &lt;id&gt;009&lt;/id&gt;</span></span><br><span class="line"><span class="string">            &lt;name&gt;Brent&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;/user&gt;</span></span><br><span class="line"><span class="string">    &lt;/users&gt;</span></span><br><span class="line"><span class="string">&lt;/stuff&gt;'''</span></span><br><span class="line"></span><br><span class="line">stuff = ET.fromstring(input)</span><br><span class="line">lst = stuff.findall(<span class="string">'users/user'</span>)</span><br><span class="line">print(<span class="string">'User count:'</span>, len(lst))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> lst:</span><br><span class="line">    print(<span class="string">'Name'</span>, item.find(<span class="string">'name'</span>).text)</span><br><span class="line">    print(<span class="string">'Id'</span>, item.find(<span class="string">'id'</span>).text)</span><br><span class="line">    print(<span class="string">'Attribute'</span>, item.get(<span class="string">"x"</span>))</span><br></pre></td></tr></table></figure>
<p>Output:</p>
<blockquote>
<p>User count: 2<br>Name Chuck<br>Id 001<br>Attribute 2<br>Name Brent<br>Id 009<br>Attribute 7</p>
</blockquote>
<p>Note:</p>
<blockquote>
<p>It is important to includes all parents level elements in the <strong>findall</strong> statement except for the top level element. Otherwise, Python will not find any desired nodes.</p>
</blockquote>
<h2 id="13-4-JavaScript-Object-Notation-JSON"><a href="#13-4-JavaScript-Object-Notation-JSON" class="headerlink" title="13.4 JavaScript Object Notation - JSON"></a>13.4 JavaScript Object Notation - JSON</h2><blockquote>
<p>The JSON format was inspired by the object and array format used in the JavaScript language. But since Python was invented before JavaScript, Python’s syntax for dictionaries and lists influenced the syntax of JSON. So the format of JSON is nearly identical to a combination of Python lists and dictionaries.</p>
</blockquote>
<p>Here is a JSON encoding that is roughly equivalent to the simple XML from above:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span> : <span class="string">"Chuck"</span>,</span><br><span class="line">  <span class="attr">"phone"</span> : &#123;</span><br><span class="line">    <span class="attr">"type"</span> : <span class="string">"intl"</span>,</span><br><span class="line">    <span class="attr">"number"</span> : <span class="string">"+1 734 303 4456"</span></span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="attr">"email"</span> : &#123;</span><br><span class="line">     <span class="attr">"hide"</span> : <span class="string">"yes"</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>In XML, we can add attributes like “intl” to the “phone” tag.<br>In JSON, we simply have key-value pairs. Also the XML “person” tag is gone, replaced by a set of outer curly braces.</p>
<p>In general, JSON structures are simpler than XML because JSON has fewer capabilities than XML. But JSON has the advantage that it maps <em>directly</em> to some combination of dictionaries and lists. And since nearly all programming languages have something equivalent to Python’s dictionaries and lists, JSON is a very natural format to have two cooperating programs exchange data.</p>
<p>JSON is quickly becoming the format of choice for nearly all data exchange between applications because of its relative simplicity compared to XML.</p>
</blockquote>
<h2 id="13-5-Parsing-JSON"><a href="#13-5-Parsing-JSON" class="headerlink" title="13.5 Parsing JSON"></a>13.5 Parsing JSON</h2><blockquote>
<p>We construct our JSON by nesting dictionaries (objects) and lists as needed. In this example, we represent a list of users where each user is a set of key-value pairs (i.e., a dictionary). So we have a list of dictionaries.</p>
<p>In the following program, we use the built-in <em>json</em> library to parse the JSON and read through the data. Compare this closely to the equivalent XML data and code above. The JSON has less detail, so we must know in advance that we are getting a list and that the list is of users and each user is a set of key-value pairs. The JSON is more succinct (an advantage) but also is less self-describing (a disadvantage).</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Code: http://www.py4e.com/code3/json2.py</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">data = <span class="string">'''</span></span><br><span class="line"><span class="string">[</span></span><br><span class="line"><span class="string">  &#123; "id" : "001",</span></span><br><span class="line"><span class="string">    "x" : "2",</span></span><br><span class="line"><span class="string">    "name" : "Chuck"</span></span><br><span class="line"><span class="string">  &#125; ,</span></span><br><span class="line"><span class="string">  &#123; "id" : "009",</span></span><br><span class="line"><span class="string">    "x" : "7",</span></span><br><span class="line"><span class="string">    "name" : "Chuck"</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">]'''</span></span><br><span class="line"></span><br><span class="line">info = json.loads(data)</span><br><span class="line">print(<span class="string">'User count:'</span>, len(info))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> info:</span><br><span class="line">    print(<span class="string">'Name'</span>, item[<span class="string">'name'</span>])</span><br><span class="line">    print(<span class="string">'Id'</span>, item[<span class="string">'id'</span>])</span><br><span class="line">    print(<span class="string">'Attribute'</span>, item[<span class="string">'x'</span>])</span><br></pre></td></tr></table></figure>
<p>Output:</p>
<blockquote>
<p>User count: 2<br>Name Chuck<br>Id 001<br>Attribute 2<br>Name Chuck<br>Id 009<br>Attribute 7</p>
</blockquote>
<ul>
<li>we get from <em>json.loads()</em> is a Python list which we traverse with a <code>for</code> loop, and each item within that list is a Python dictionary.</li>
<li>In general, there is an industry trend away from XML and towards JSON for web services. </li>
<li>But XML is more self-descriptive than JSON and so there are some applications where XML retains an advantage. For example, most word processors store documents internally using XML rather than JSON.</li>
</ul>
<h2 id="13-6-Application-Programming-Interfaces-API"><a href="#13-6-Application-Programming-Interfaces-API" class="headerlink" title="13.6 Application Programming Interfaces - API"></a>13.6 Application Programming Interfaces - API</h2><blockquote>
<p><strong>API</strong><br>A contract between applications that defines the patterns of interaction between two application components</p>
<p><strong>SOA</strong><br>When we begin to build our programs where the functionality of our program includes access to services provided by other programs, we call the approach a <em>Service-Oriented Architecture</em> or SOA. (A non-SOA approach is where the application is a single standalone application which contains all of the code necessary to implement the application.)</p>
</blockquote>
<p>We see many examples of SOA when we use the web. We can go to a single web site and book air travel, hotels, and automobiles all from a single site. The data for hotels is not stored on the airline computers. Instead, the airline computers contact the services on the hotel computers and retrieve the hotel data and present it to the user. When the user agrees to make a hotel reservation using the airline site, the airline site uses another web service on the hotel systems to actually make the reservation. And when it comes time to charge your credit card for the whole transaction, still other computers become involved in the process.</p>
<p><img src="/assets/image-20200215104121294.png" alt="API_SOA" style="zoom:80%;" /></p>
<blockquote>
<p>When an application makes a set of services in its API available over the web, we call these <strong><em>web services</em></strong>.</p>
</blockquote>
<h2 id="13-7-Security-and-API-usage"><a href="#13-7-Security-and-API-usage" class="headerlink" title="13.7 Security and API usage"></a>13.7 Security and API usage</h2><blockquote>
<p>It is quite common that you need an API key to make use of a vendor’s API.<br>The general idea is that they want to know who is using their services and how much each user is using.</p>
<p>Sometimes once you get your API key, you simply include the key as part of POST data or perhaps as a parameter on the URL when calling the API.<br>Other times, the vendor wants increased assurance of the source of the requests and so they add expect you to send cryptographically signed messages using shared keys and secrets.</p>
<p> A very common technology that is used to sign requests over the Internet is called <a href="www.oauth.net"><em>OAuth</em></a>.</p>
</blockquote>
<h2 id="13-8-Application"><a href="#13-8-Application" class="headerlink" title="13.8 Application"></a>13.8 Application</h2><h3 id="13-8-1-Google-geocoding-web-service"><a href="#13-8-1-Google-geocoding-web-service" class="headerlink" title="13.8.1 Google geocoding web service"></a>13.8.1 Google geocoding web service</h3><blockquote>
<p><em>When you are using a free API like Google’s geocoding API, you need to be respectful in your use of these resources. If too many people abuse the service, Google might drop or significantly curtail its free service.</em></p>
</blockquote>
<p>Need API!</p>
<h3 id="13-8-2-Twitter"><a href="#13-8-2-Twitter" class="headerlink" title="13.8.2 Twitter"></a>13.8.2 Twitter</h3><blockquote>
<p>As the Twitter API became increasingly valuable, Twitter went from an open and public API to an API that required the use of OAuth signatures on each API request. </p>
</blockquote>

    </div>

    
    
    

<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------The End<i class="fa fa-paw"></i>Thanks for Reading-------------</div>
    
</div>
  
</div>
      
        <div class="reward-container">
  <div>您的支持将鼓励我继续创作！</div>
  <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat.jpg" alt="Yihang Li 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/coursera/" rel="tag"># coursera</a>
              <a href="/tags/web/" rel="tag"># web</a>
              <a href="/tags/data-access/" rel="tag"># data access</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/02/11/Summary-for-visualization-of-geospatial-data/" rel="next" title="Summary for visualization of geospatial data">
                  <i class="fa fa-chevron-left"></i> Summary for visualization of geospatial data
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/02/17/Hilbert-Space-Midterm-Review/" rel="prev" title="Hilbert Space: Midterm Review">
                  Hilbert Space: Midterm Review <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Chapter-11-Regular-expressions"><span class="nav-number">1.</span> <span class="nav-text">Chapter 11 Regular expressions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Cheat-Sheet"><span class="nav-number">1.1.</span> <span class="nav-text">Cheat Sheet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Examples"><span class="nav-number">1.2.</span> <span class="nav-text">Examples</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-1"><span class="nav-number">1.2.1.</span> <span class="nav-text">Case 1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-2"><span class="nav-number">1.2.2.</span> <span class="nav-text">Case 2</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Chapter-12-Networked-Programs"><span class="nav-number">2.</span> <span class="nav-text">Chapter 12 Networked Programs</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#12-1-Hypertext-Transfer-Protocol-HTTP"><span class="nav-number">2.1.</span> <span class="nav-text">12.1 Hypertext Transfer Protocol - HTTP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-2-The-world’s-simplest-web-browser"><span class="nav-number">2.2.</span> <span class="nav-text">12.2 The world’s simplest web browser</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-3-Retrieving-an-image-over-HTTP"><span class="nav-number">2.3.</span> <span class="nav-text">12.3 Retrieving an image over HTTP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-4-Retrieving-web-pages-with-urllib"><span class="nav-number">2.4.</span> <span class="nav-text">12.4 Retrieving web pages with urllib</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Example"><span class="nav-number">2.4.1.</span> <span class="nav-text">Example</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-5-Reading-binary-files-using-urllib"><span class="nav-number">2.5.</span> <span class="nav-text">12.5 Reading binary files using urllib</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-6-Parsing-HTML-and-scraping-the-web"><span class="nav-number">2.6.</span> <span class="nav-text">12.6 Parsing HTML and scraping the web</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-7-Parsing-HTML-using-regular-expressions"><span class="nav-number">2.7.</span> <span class="nav-text">12.7 Parsing HTML using regular expressions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-8-Parsing-HTML-using-BeautifulSoup"><span class="nav-number">2.8.</span> <span class="nav-text">12.8 Parsing HTML using BeautifulSoup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-9-Something-more"><span class="nav-number">2.9.</span> <span class="nav-text">12.9 Something more</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">2.10.</span> <span class="nav-text">Summary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#null"><span class="nav-number">3.</span> <span class="nav-text"> </span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Chapter-13-Using-Web-Services"><span class="nav-number">4.</span> <span class="nav-text">Chapter 13 Using Web Services</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#13-1-eXtensible-Markup-Language-XML"><span class="nav-number">4.1.</span> <span class="nav-text">13.1 eXtensible Markup Language - XML</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-2-Parsing-XML"><span class="nav-number">4.2.</span> <span class="nav-text">13.2 Parsing XML</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-3-Looping-through-nodes"><span class="nav-number">4.3.</span> <span class="nav-text">13.3 Looping through nodes</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-4-JavaScript-Object-Notation-JSON"><span class="nav-number">4.4.</span> <span class="nav-text">13.4 JavaScript Object Notation - JSON</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-5-Parsing-JSON"><span class="nav-number">4.5.</span> <span class="nav-text">13.5 Parsing JSON</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-6-Application-Programming-Interfaces-API"><span class="nav-number">4.6.</span> <span class="nav-text">13.6 Application Programming Interfaces - API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-7-Security-and-API-usage"><span class="nav-number">4.7.</span> <span class="nav-text">13.7 Security and API usage</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-8-Application"><span class="nav-number">4.8.</span> <span class="nav-text">13.8 Application</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#13-8-1-Google-geocoding-web-service"><span class="nav-number">4.8.1.</span> <span class="nav-text">13.8.1 Google geocoding web service</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-8-2-Twitter"><span class="nav-number">4.8.2.</span> <span class="nav-text">13.8.2 Twitter</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Yihang Li"
    src="https://s2.ax1x.com/2020/02/06/1yubPU.jpg">
  <p class="site-author-name" itemprop="name">Yihang Li</p>
  <div class="site-description" itemprop="description">description here</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Yihang-Li" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;Yihang-Li" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liyihang970727@gmail.com" title="E-Mail &amp;rarr; mailto:liyihang970727@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/YihangLi8" title="Twitter &amp;rarr; https:&#x2F;&#x2F;twitter.com&#x2F;YihangLi8" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/yihang.li.710" title="FB Page &amp;rarr; https:&#x2F;&#x2F;www.facebook.com&#x2F;yihang.li.710" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i>FB Page</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-star"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yihang Li</span>
</div>

<span id="busuanzi_container_site_uv">
  本站访客数：<span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
</span>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共8.3k字</span>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

</body>
</html>
